// -----------------------------------------------------------------------
// <copyright file="SampleGenerator.cs" company="No company">
//  Authors: B. Thirion, G. Varoquaux, A. Gramfort, V. Michel, O. Grisel,
//          G. Louppe, S. Zyuzin
//  License: BSD 3 clause
// </copyright>
// -----------------------------------------------------------------------

namespace Sharpkit.Learn.Datasets
{
    using System;
    using System.Linq;
    using MathNet.Numerics.Distributions;
    using MathNet.Numerics.LinearAlgebra.Double;
    using MathNet.Numerics.LinearAlgebra.Generic.Factorization;

    /// <summary>
    /// Generate samples of synthetic data sets.
    /// </summary>
    public class SampleGenerator
    {
        /// <summary>
        /// Generate a random regression problem.
        /// <para>
        /// The input set can either be well conditioned (by default) or have a low
        /// rank-fat tail singular profile. See <see cref="MakeLowRankMatrix"/> for
        /// more details.
        /// </para>
        /// <para>
        /// The output is generated by applying a (potentially biased) random linear
        /// regression model with `numInformative` nonzero regressors to the previously
        /// generated input and some gaussian centered noise with some adjustable
        /// scale.
        /// </para>
        /// </summary>
        /// <param name="numSamples">The number of samples.</param>
        /// <param name="numFeatures">The number of features.</param>
        /// <param name="numInformative">The number of informative features, i.e., the number of features used
        /// to build the linear model used to generate the output.</param>
        /// <param name="numTargets">The number of regression targets, i.e., the dimension of the y output
        /// vector associated with a sample. By default, the output is a scalar.</param>
        /// <param name="bias">The bias term in the underlying linear model.</param>
        /// <param name="effectiveRank">if not null:
        ///   The approximate number of singular vectors required to explain most
        ///   of the input data by linear combinations. Using this kind of
        ///   singular spectrum in the input allows the generator to reproduce
        ///   the correlations often observed in practice.
        ///   if null:
        ///       The input set is well conditioned, centered and gaussian with
        ///       unit variance.</param>
        /// <param name="tailStrength">Value between 0.0 and 1.0.
        /// The relative importance of the fat noisy tail of the singular values
        /// profile if <paramref name="effectiveRank"/> is not None.</param>
        /// <param name="noise">The standard deviation of the gaussian noise applied to the output.</param>
        /// <param name="shuffle">Shuffle the samples and the features.</param>
        /// <param name="coef">If <c>true</c>, the coefficients of the underlying linear model are returned.</param>
        /// <param name="random">Instance of <see cref="Random"/>.</param>
        /// <returns>Instance of <see cref="RegressionResult"/>.</returns>
        public static RegressionResult MakeRegression(
            int numSamples = 100,
            int numFeatures = 100,
            int numInformative = 10,
            int numTargets = 1,
            double bias = 0.0,
            int? effectiveRank = null,
            double tailStrength = 0.5,
            double noise = 0.0,
            bool shuffle = true,
            bool coef = false,
            Random random = null)
        {
            var generator = random ?? new Random();

            Matrix x;
            Matrix y;
            if (effectiveRank == null)
            {
                // Randomly generate a well conditioned input set
                x = DenseMatrix.CreateRandom(
                    numSamples,
                    numFeatures,
                    new ContinuousUniform { RandomSource = generator });
            }
            else
            {
                // Randomly generate a low rank, fat tail input set
                x = MakeLowRankMatrix(
                    numSamples,
                    numFeatures,
                    effectiveRank.Value,
                    tailStrength,
                    generator);
            }
    
            // Generate a ground truth model with only 'numInformative' features being non
            // zeros (the other features are not correlated to y and should be ignored
            // by a sparsifying regularizers such as L1 or elastic net)
            Matrix groundTruth = DenseMatrix.CreateRandom(numFeatures, numTargets, new ContinuousUniform(0, 100));
            groundTruth.MapIndexedInplace((i, j, v) => i >= numInformative ? 0 : v);

            y = (Matrix)(x * groundTruth);
            y.MapInplace(v => v + bias);

            // Add noise
            if (noise > 0.0)
            {
                var normalDistribution = new Normal { RandomSource = generator };
                DenseMatrix randomMatrix = DenseMatrix.CreateRandom(y.RowCount, y.ColumnCount, normalDistribution);
                y = (Matrix)(y + (randomMatrix * noise));
            }

            // Randomly permute samples and features
            if (shuffle)
            {
                // todo:
                throw new ArgumentException("Shuffle is not yet supported");
            }

            if (coef)
            {
                return new RegressionResult { X = x, Y = y, Coef = groundTruth };
            }

            return new RegressionResult { X = x, Y = y };
        }

        /// <summary>
        /// Generate a mostly low rank matrix with bell-shaped singular values
        /// <para>
        /// Most of the variance can be explained by a bell-shaped curve of width
        /// effective_rank: the low rank part of the singular values profile is:
        /// </para>
        /// <para>
        /// (1 - tailStrength) * exp(-1.0 * (i / effectiveRank) ** 2)
        /// </para>
        /// <para>
        /// The remaining singular values' tail is fat, decreasing as:
        /// </para>
        /// <para>
        /// tailStrength * exp(-0.1 * i / effectiveRank).
        /// </para>
        /// <para>
        /// The low rank part of the profile can be considered the structured
        /// signal part of the data while the tail can be considered the noisy
        /// part of the data that cannot be summarized by a low number of linear
        /// components (singular vectors).
        /// </para>
        /// <para>
        /// This kind of singular profiles is often seen in practice, for instance:
        ///   - gray level pictures of faces
        ///   - TF-IDF vectors of text documents crawled from the web
        /// </para>
        /// </summary>
        /// <param name="numSamples">The number of samples.</param>
        /// <param name="numFeatures">The number of features.</param>
        /// <param name="effectiveRank">The approximate number of singular vectors required to explain most of
        /// the data by linear combinations.</param>
        /// <param name="tailStrength">The relative importance of the fat noisy tail of the singular values
        /// profile.</param>
        /// <param name="randomState">Instance of <see cref="Random"/>.</param>
        /// <returns>The matrix.</returns>
        public static Matrix MakeLowRankMatrix(
            int numSamples = 100,
            int numFeatures = 100,
            int effectiveRank = 10,
            double tailStrength = 0.5,
            Random randomState = null)
        {
            Random generator = randomState ?? new Random();
            int n = Math.Min(numSamples, numFeatures);

            // Random (ortho normal) vectors
            var normalDistribution = new Normal { RandomSource = generator };
            Matrix u = (Matrix)DenseMatrix.CreateRandom(numSamples, n, normalDistribution).QR(QRMethod.Thin).Q;
            Matrix v = (Matrix)DenseMatrix.CreateRandom(numFeatures, n, normalDistribution).QR(QRMethod.Thin).Q;

            // Index of the singular values
            var singularInd = DenseVector.OfEnumerable(Enumerable.Range(0, n).Select(val => (double)val));

            // Build the singular profile by assembling signal and noise components
            Vector vect = singularInd / effectiveRank;
            vect.MapInplace(val => Math.Exp(-val * val));
            Vector lowRank = (Vector)((1 - tailStrength) * vect);

            vect = singularInd / effectiveRank;
            vect.MapInplace(val => Math.Exp(-0.1 * val));
            Vector tail = (Vector)(tailStrength * vect);
            var s = DenseMatrix.Identity(n).MulRowVector((Vector)(lowRank + tail));

            return (Matrix)(u * s * v.Transpose());
        }

        /// <summary>
        /// Generate a random regression problem with sparse uncorrelated design
        /// <para>
        /// This dataset is described in Celeux et al [1]. as::
        /// </para>
        /// <para>
        /// X ~ N(0, 1)
        /// y(X) = X[:, 0] + 2 * X[:, 1] - 2 * X[:, 2] - 1.5 * X[:, 3]
        /// </para>
        /// <para>
        /// Only the first 4 features are informative. The remaining features are
        /// useless.
        /// </para>
        /// </summary>
        /// <param name="numSamples">The number of samples.</param>
        /// <param name="numFeatures">The number of features.</param>
        /// <param name="random">Instance of <see cref="Random"/>.</param>
        /// <returns>Instance of <see cref="RegressionResult"/> with <see cref="RegressionResult.Coef"/> not populated.</returns>
        /// <remarks>
        ///     References
        ///     ----------
        ///      .. [1] G. Celeux, M. El Anbari, J.-M. Marin, C. P. Robert,
        ///       "Regularization in regression: comparing Bayesian and frequentist
        ///        methods in a poorly informative situation", 2009.
        /// </remarks>
        public static RegressionResult MakeSparseUncorrelated(
            int numSamples = 100,
            int numFeatures = 10,
            Random random = null)
        {
            var distribution = new Normal(0, 1) { RandomSource = random };
            Matrix x = DenseMatrix.CreateRandom(numSamples, numFeatures, distribution);

            Vector y = new DenseVector(numSamples);
            for (int i = 0; i < numSamples; i++)
            {
                var mean = x[i, 0] + (2 * x[i, 1]) - (2 * x[i, 2]) - (1.5 * x[i, 3]);
                y[i] = new Normal(mean, 1.0) { RandomSource = random }.Sample();
            }

            return new RegressionResult { X = x, Y = y.ToDenseMatrix() };
        }

        /// <summary>
        /// Regression result.
        /// </summary>
        public class RegressionResult
        {
            /// <summary>
            /// Initializes a new instance of the RegressionResult class.
            /// </summary>
            internal RegressionResult()
            {
            }

            /// <summary>
            /// Gets the input samples.
            /// </summary>
            public Matrix X { get; internal set; }

            /// <summary>
            /// Gets the output values.
            /// </summary>
            public Matrix Y { get; internal set; }

            /// <summary>
            /// Gets the coefficient of the underlying linear model.
            /// </summary>
            public Matrix Coef { get; internal set; }
        }
    }
}
